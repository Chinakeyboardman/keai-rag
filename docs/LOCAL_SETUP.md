# ğŸ  å®Œå…¨æœ¬åœ°åŒ–éƒ¨ç½²æŒ‡å—ï¼ˆæ— éœ€ API Keyï¼‰

æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨åœ¨**å®Œå…¨ä¸éœ€è¦ä»»ä½• API Key** çš„æƒ…å†µä¸‹è¿è¡Œ RAG ç³»ç»Ÿã€‚

---

## ğŸ“‹ æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | Embedding | LLM | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|-----------|-----|------|------|
| **æ–¹æ¡ˆä¸€ï¼ˆæ¨èï¼‰** | æœ¬åœ°å°æ¨¡å‹ | Ollama | å®Œå…¨å…è´¹ï¼Œæ˜“å®‰è£… | éœ€è¦ä¸‹è½½æ¨¡å‹ |
| **æ–¹æ¡ˆäºŒ** | æœ¬åœ°å°æ¨¡å‹ | æœ¬åœ°å¤§æ¨¡å‹ | å®Œå…¨ç¦»çº¿ | éœ€è¦å¤§é‡å†…å­˜ |
| **æ–¹æ¡ˆä¸‰** | æœ¬åœ°å°æ¨¡å‹ | å›½å†…å…è´¹API | å¿«é€Ÿå¯åŠ¨ | éœ€è¦æ³¨å†Œè´¦å· |

---

## ğŸš€ æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨ Ollamaï¼ˆæœ€æ¨èï¼‰

### ä¼˜ç‚¹
- âœ… å®Œå…¨å…è´¹
- âœ… å®‰è£…ç®€å•
- âœ… æ¨¡å‹è´¨é‡å¥½
- âœ… å†…å­˜å ç”¨å°ï¼ˆçº¦ 4-8GBï¼‰

### æ­¥éª¤

#### 1. å®‰è£… Ollama

```bash
# macOS
brew install ollama

# æˆ–è€…ä»å®˜ç½‘ä¸‹è½½
# https://ollama.ai/download
```

#### 2. å¯åŠ¨ Ollama æœåŠ¡

```bash
# å¯åŠ¨ Ollamaï¼ˆä¼šåœ¨åå°è¿è¡Œï¼‰
ollama serve
```

#### 3. ä¸‹è½½æ¨¡å‹

```bash
# ä¸‹è½½ä¸­æ–‡æ¨¡å‹ Qwen2ï¼ˆæ¨èï¼Œçº¦ 4GBï¼‰
ollama pull qwen2:7b

# æˆ–è€…æ›´å°çš„æ¨¡å‹ï¼ˆçº¦ 2GBï¼‰
ollama pull qwen2:1.5b

# æˆ–è€…è‹±æ–‡æ¨¡å‹
ollama pull llama3.2:3b
```

#### 4. é…ç½®é¡¹ç›®

```bash
# å¤åˆ¶æœ¬åœ°é…ç½®
cp .env.local .env

# æˆ–æ‰‹åŠ¨åˆ›å»º .env æ–‡ä»¶ï¼Œå†…å®¹å¦‚ä¸‹ï¼š
cat > .env << 'EOF'
USE_QDRANT=false
VECTOR_DIMENSION=384

# Embedding ä½¿ç”¨å°æ¨¡å‹
EMBEDDING_MODEL_TYPE=local
EMBEDDING_MODEL_NAME=paraphrase-MiniLM-L6-v2

# LLM ä½¿ç”¨ Ollama
LLM_MODEL_TYPE=api
LLM_MODEL_NAME=qwen2:7b
LLM_API_BASE=http://localhost:11434/v1
LLM_API_KEY=ollama
EOF
```

#### 5. å®‰è£… Python ä¾èµ–

```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# å®‰è£… Embedding æ¨¡å‹ä¾èµ–
pip install sentence-transformers
```

#### 6. å¯åŠ¨é¡¹ç›®

```bash
./start.sh
```

---

## ğŸ¯ æ–¹æ¡ˆäºŒï¼šå®Œå…¨ç¦»çº¿ï¼ˆä½¿ç”¨æœ¬åœ°å¤§æ¨¡å‹ï¼‰

### é€‚åˆåœºæ™¯
- å®Œå…¨ç¦»çº¿ç¯å¢ƒ
- æœ‰è¶³å¤Ÿçš„ç¡¬ä»¶èµ„æºï¼ˆ16GB+ RAMï¼‰

### æ­¥éª¤

#### 1. ä¸‹è½½æ¨¡å‹

```bash
# ä¸‹è½½ Embedding æ¨¡å‹ï¼ˆè‡ªåŠ¨ï¼‰
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('paraphrase-MiniLM-L6-v2')"

# ä¸‹è½½ LLM æ¨¡å‹ï¼ˆéœ€è¦æ‰‹åŠ¨ï¼‰
# æ¨èï¼šQwen2-7B-Instruct æˆ– ChatGLM3-6B
```

#### 2. é…ç½® .env

```bash
USE_QDRANT=false
VECTOR_DIMENSION=384

# Embedding
EMBEDDING_MODEL_TYPE=local
EMBEDDING_MODEL_NAME=paraphrase-MiniLM-L6-v2

# LLMï¼ˆéœ€è¦æŒ‡å®šæ¨¡å‹è·¯å¾„ï¼‰
LLM_MODEL_TYPE=local
LLM_MODEL_PATH=/path/to/your/model
```

#### 3. å¯åŠ¨

```bash
./start.sh
```

---

## ğŸŒ æ–¹æ¡ˆä¸‰ï¼šä½¿ç”¨å›½å†…å…è´¹ API

### å¯ç”¨çš„å…è´¹ API

#### 1. é˜¿é‡Œäº‘é€šä¹‰åƒé—®ï¼ˆæ¨èï¼‰

**å…è´¹é¢åº¦**: æ¯å¤© 100 ä¸‡ tokens

```bash
# æ³¨å†Œåœ°å€ï¼šhttps://dashscope.aliyun.com/
# è·å– API Key åé…ç½®ï¼š

USE_QDRANT=false
VECTOR_DIMENSION=1536

# Embeddingï¼ˆæœ¬åœ°ï¼‰
EMBEDDING_MODEL_TYPE=local
EMBEDDING_MODEL_NAME=paraphrase-MiniLM-L6-v2

# LLMï¼ˆAPIï¼‰
LLM_MODEL_TYPE=api
LLM_MODEL_NAME=qwen-turbo
LLM_API_KEY=your_dashscope_api_key
LLM_API_BASE=https://dashscope.aliyuncs.com/compatible-mode/v1
```

#### 2. DeepSeekï¼ˆæ¨èï¼‰

**å…è´¹é¢åº¦**: æ¯å¤© 500 ä¸‡ tokens

```bash
# æ³¨å†Œåœ°å€ï¼šhttps://platform.deepseek.com/
# è·å– API Key åé…ç½®ï¼š

LLM_MODEL_TYPE=api
LLM_MODEL_NAME=deepseek-chat
LLM_API_KEY=your_deepseek_api_key
LLM_API_BASE=https://api.deepseek.com/v1
```

#### 3. æ™ºè°± AIï¼ˆGLMï¼‰

**å…è´¹é¢åº¦**: æ¯æœˆ 100 ä¸‡ tokens

```bash
# æ³¨å†Œåœ°å€ï¼šhttps://open.bigmodel.cn/
# è·å– API Key åé…ç½®ï¼š

LLM_MODEL_TYPE=api
LLM_MODEL_NAME=glm-4-flash
LLM_API_KEY=your_zhipu_api_key
LLM_API_BASE=https://open.bigmodel.cn/api/paas/v4
```

---

## ğŸ” æ–¹æ¡ˆå¯¹æ¯”è¯¦ç»†

### Embedding æ¨¡å‹é€‰æ‹©

| æ¨¡å‹ | å¤§å° | ç»´åº¦ | è¯­è¨€ | æ¨èåº¦ | è¯´æ˜ |
|------|------|------|------|--------|------|
| **paraphrase-multilingual-MiniLM-L12-v2** | 420MB | 384 | ğŸŒ 50+è¯­è¨€ | â­â­â­â­â­ | **æ¨èï¼å¤šè¯­è¨€å°æ¨¡å‹** |
| **paraphrase-multilingual-mpnet-base-v2** | 1GB | 768 | ğŸŒ 50+è¯­è¨€ | â­â­â­â­â­ | å¤šè¯­è¨€é«˜è´¨é‡ |
| **distiluse-base-multilingual-cased-v2** | 500MB | 512 | ğŸŒ 50+è¯­è¨€ | â­â­â­â­ | å¹³è¡¡æ€§èƒ½ |
| paraphrase-MiniLM-L6-v2 | 80MB | 384 | ğŸ‡¬ğŸ‡§ è‹±æ–‡ | â­â­â­â­ | è‹±æ–‡ä¸“ç”¨ |
| text2vec-base-chinese | 400MB | 768 | ğŸ‡¨ğŸ‡³ ä¸­æ–‡ | â­â­â­â­ | ä¸­æ–‡ä¸“ç”¨ |
| m3e-base | 400MB | 768 | ğŸ‡¨ğŸ‡³ ä¸­æ–‡ | â­â­â­â­ | ä¸­æ–‡ä¸“ç”¨ |

### LLM æ¨¡å‹é€‰æ‹©

| æ–¹æ¡ˆ | å¤§å° | å†…å­˜éœ€æ±‚ | è´¨é‡ | æ¨èåº¦ |
|------|------|----------|------|--------|
| Ollama (qwen2:7b) | 4GB | 8GB | é«˜ | â­â­â­â­â­ |
| Ollama (qwen2:1.5b) | 2GB | 4GB | ä¸­ | â­â­â­â­ |
| é€šä¹‰åƒé—® API | 0 | 0 | é«˜ | â­â­â­â­ |
| DeepSeek API | 0 | 0 | é«˜ | â­â­â­â­ |

---

## ğŸ“¦ å¿«é€Ÿå®‰è£…è„šæœ¬

### ä¸€é”®å®‰è£… Ollama æ–¹æ¡ˆ

```bash
#!/bin/bash

echo "ğŸš€ å®‰è£… Ollama æœ¬åœ°æ–¹æ¡ˆ..."

# 1. å®‰è£… Ollama
if ! command -v ollama &> /dev/null; then
    echo "ğŸ“¦ å®‰è£… Ollama..."
    brew install ollama
fi

# 2. å¯åŠ¨ Ollama
echo "ğŸ”„ å¯åŠ¨ Ollama æœåŠ¡..."
ollama serve &
sleep 5

# 3. ä¸‹è½½æ¨¡å‹
echo "ğŸ“¥ ä¸‹è½½ Qwen2 æ¨¡å‹ï¼ˆçº¦ 4GBï¼‰..."
ollama pull qwen2:7b

# 4. é…ç½®é¡¹ç›®
echo "âš™ï¸  é…ç½®é¡¹ç›®..."
cd /Users/chenjiawei/Study/ai/zhihu/13-Embeddingså’Œå‘é‡æ•°æ®åº“/china-pdf-rag
cp .env.local .env

# 5. å®‰è£…ä¾èµ–
echo "ğŸ“¦ å®‰è£… Python ä¾èµ–..."
source venv/bin/activate
pip install sentence-transformers

echo "âœ… å®‰è£…å®Œæˆï¼"
echo ""
echo "è¿è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨é¡¹ç›®ï¼š"
echo "  ./start.sh"
```

ä¿å­˜ä¸º `install_ollama.sh`ï¼Œç„¶åè¿è¡Œï¼š

```bash
chmod +x install_ollama.sh
./install_ollama.sh
```

---

## âš¡ æ€§èƒ½å¯¹æ¯”

### ç¡¬ä»¶éœ€æ±‚

| é…ç½® | CPU | RAM | ç£ç›˜ | å“åº”æ—¶é—´ |
|------|-----|-----|------|----------|
| æœ€å°é…ç½® | 4æ ¸ | 4GB | 5GB | 5-10ç§’ |
| æ¨èé…ç½® | 8æ ¸ | 8GB | 10GB | 2-5ç§’ |
| é«˜æ€§èƒ½é…ç½® | 16æ ¸ | 16GB | 20GB | 1-2ç§’ |

### æ¨¡å‹ä¸‹è½½æ—¶é—´ï¼ˆå‚è€ƒï¼‰

| æ¨¡å‹ | å¤§å° | ä¸‹è½½æ—¶é—´ï¼ˆ100Mbpsï¼‰ |
|------|------|---------------------|
| paraphrase-MiniLM-L6-v2 | 80MB | 10ç§’ |
| qwen2:1.5b | 2GB | 3åˆ†é’Ÿ |
| qwen2:7b | 4GB | 6åˆ†é’Ÿ |

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: Ollama è¿æ¥å¤±è´¥

```bash
# æ£€æŸ¥ Ollama æ˜¯å¦è¿è¡Œ
ps aux | grep ollama

# é‡å¯ Ollama
pkill ollama
ollama serve
```

### Q2: æ¨¡å‹ä¸‹è½½æ…¢

```bash
# ä½¿ç”¨å›½å†…é•œåƒ
export OLLAMA_HOST=https://ollama.com
ollama pull qwen2:7b
```

### Q3: å†…å­˜ä¸è¶³

```bash
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
ollama pull qwen2:1.5b

# æˆ–åœ¨ .env ä¸­è®¾ç½®
LLM_MODEL_NAME=qwen2:1.5b
```

### Q4: Embedding æ¨¡å‹ä¸‹è½½å¤±è´¥

```bash
# æ‰‹åŠ¨ä¸‹è½½
python << EOF
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')
print("âœ… æ¨¡å‹ä¸‹è½½æˆåŠŸ")
EOF
```

---

## ğŸ¯ æ¨èé…ç½®

### ä¸ªäººä½¿ç”¨ï¼ˆæœ€ç®€å•ï¼‰

```bash
# .env é…ç½®
USE_QDRANT=false
EMBEDDING_MODEL_TYPE=local
EMBEDDING_MODEL_NAME=paraphrase-MiniLM-L6-v2
VECTOR_DIMENSION=384

LLM_MODEL_TYPE=api
LLM_MODEL_NAME=qwen2:7b
LLM_API_BASE=http://localhost:11434/v1
LLM_API_KEY=ollama
```

### ä¼ä¸šä½¿ç”¨ï¼ˆé«˜æ€§èƒ½ï¼‰

```bash
# .env é…ç½®
USE_QDRANT=true
QDRANT_URL=http://localhost:6333

EMBEDDING_MODEL_TYPE=local
EMBEDDING_MODEL_NAME=text2vec-base-chinese
VECTOR_DIMENSION=768

LLM_MODEL_TYPE=api
LLM_MODEL_NAME=qwen2:7b
LLM_API_BASE=http://localhost:11434/v1
LLM_API_KEY=ollama
```

---

## âœ… éªŒè¯å®‰è£…

```bash
# 1. æµ‹è¯• Ollama
curl http://localhost:11434/api/generate -d '{
  "model": "qwen2:7b",
  "prompt": "ä½ å¥½"
}'

# 2. æµ‹è¯• Embedding
python -c "
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')
print('âœ… Embedding æ¨¡å‹æ­£å¸¸')
"

# 3. å¯åŠ¨é¡¹ç›®
./start.sh
```

---

**é€‰æ‹©æ–¹æ¡ˆä¸€ï¼ˆOllamaï¼‰æ˜¯æœ€ç®€å•ä¸”æ•ˆæœæœ€å¥½çš„æ–¹æ¡ˆï¼** ğŸ‰

