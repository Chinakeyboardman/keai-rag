#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ£€ç´¢æœåŠ¡
è´Ÿè´£æ–‡æ¡£æ£€ç´¢å’Œç›¸å…³æ€§è®¡ç®—
"""

from typing import List, Dict, Any, Optional
import numpy as np

from src.core.vector_store import BaseVectorStore, VectorSearchResult
from src.services.embedding_service import get_embedding_service
from config.settings import settings


class RetrievalService:
    """æ£€ç´¢æœåŠ¡ç±»"""
    
    def __init__(self, vector_store: BaseVectorStore):
        """
        åˆå§‹åŒ–æ£€ç´¢æœåŠ¡
        
        Args:
            vector_store: å‘é‡å­˜å‚¨å®ä¾‹
        """
        self.vector_store = vector_store
        self.embedding_service = get_embedding_service()
        self.top_k = settings.RETRIEVAL_TOP_K
    
    def retrieve(
        self,
        query: str,
        top_k: Optional[int] = None,
        filter_dict: Optional[Dict[str, Any]] = None
    ) -> List[VectorSearchResult]:
        """
        æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼ˆæ··åˆæ£€ç´¢ï¼šå‘é‡æ£€ç´¢ + å…³é”®è¯æ£€ç´¢ï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            filter_dict: è¿‡æ»¤æ¡ä»¶
            
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        if not query or not query.strip():
            raise ValueError("æŸ¥è¯¢æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
        
        # ä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼ï¼Œä½†å¢åŠ æ£€ç´¢æ•°é‡ä»¥æé«˜å¬å›ç‡
        if top_k is None:
            top_k = max(self.top_k, 15)  # è‡³å°‘æ£€ç´¢15ä¸ªç»“æœä»¥æé«˜å¬å›ç‡
        else:
            top_k = max(top_k, 15)  # ç¡®ä¿è‡³å°‘æ£€ç´¢15ä¸ªç»“æœ
        
        # æŸ¥è¯¢æ‰©å±•ï¼šå¯¹äºçŸ­æŸ¥è¯¢ï¼ˆç‰¹åˆ«æ˜¯æ•°å­—ç¼–å·ï¼‰ï¼Œæ‰©å±•æŸ¥è¯¢ä»¥æä¾›æ›´å¤šä¸Šä¸‹æ–‡
        expanded_query = self._expand_query(query)
        if expanded_query != query:
            from src.utils.logger import logger
            logger.info(f"ğŸ” æŸ¥è¯¢æ‰©å±•: \"{query}\" -> \"{expanded_query}\"")
        
        # å‘é‡åŒ–æŸ¥è¯¢ï¼ˆä½¿ç”¨æ‰©å±•åçš„æŸ¥è¯¢ï¼‰
        query_vector = self.embedding_service.embed_text(expanded_query)
        
        # å‘é‡æœç´¢ï¼ˆå¤§å¹…å¢åŠ æ£€ç´¢æ•°é‡ä»¥ç¡®ä¿ä¸é—æ¼ï¼‰
        # æ£€ç´¢æ‰€æœ‰å¯èƒ½çš„æ–‡æ¡£å—ï¼ˆå¦‚æœæ€»æ•°ä¸å¤šçš„è¯ï¼‰
        search_k = min(top_k * 3, 100)  # æ£€ç´¢æ›´å¤šç»“æœï¼Œæœ€å¤š100ä¸ªï¼Œç¡®ä¿ä¸é—æ¼
        vector_results = self.vector_store.search(
            query_vector=query_vector,
            top_k=search_k,
            filter_dict=filter_dict
        )
        
        # å…³é”®è¯å¢å¼ºï¼šæå‡åŒ…å«æŸ¥è¯¢å…³é”®è¯çš„ç»“æœçš„ä¼˜å…ˆçº§
        # æå–æŸ¥è¯¢ä¸­çš„å…³é”®çŸ­è¯­ï¼ˆå¦‚"ç¬¬åä¸€æ¡"ã€"ç”³æŠ¥æ—¶é—´"ç­‰ï¼‰
        query_lower = query.lower()
        important_phrases = []
        
        # æ£€æµ‹æ•°å­—ç¼–å·ï¼ˆå¦‚"ç¬¬åä¸€æ¡"ã€"ç¬¬ä¸€æ¡"ç­‰ï¼‰
        import re
        number_patterns = re.findall(r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+æ¡', query)
        important_phrases.extend(number_patterns)
        
        # æ£€æµ‹å…¶ä»–é‡è¦å…³é”®è¯ï¼ˆé•¿åº¦>=2çš„ä¸­æ–‡è¯ï¼‰
        chinese_words = re.findall(r'[\u4e00-\u9fa5]{2,}', query)
        important_phrases.extend([w for w in chinese_words if len(w) >= 2])
        
        # å¦‚æœæ‰¾åˆ°é‡è¦çŸ­è¯­ï¼Œæå‡åŒ…å«è¿™äº›çŸ­è¯­çš„ç»“æœçš„åˆ†æ•°
        if important_phrases:
            from src.utils.logger import logger
            logger.info(f"ğŸ” æ£€æµ‹åˆ°é‡è¦çŸ­è¯­: {important_phrases}")
            
            boosted_results = []
            exact_match_results = []
            
            for result in vector_results:
                text_lower = result.text.lower()
                # æ£€æŸ¥æ˜¯å¦åŒ…å«é‡è¦çŸ­è¯­
                contains_phrase = any(phrase in text_lower or phrase in result.text for phrase in important_phrases)
                
                if contains_phrase:
                    # åŒ…å«é‡è¦çŸ­è¯­çš„ç»“æœï¼Œæå‡åˆ†æ•°å¹¶ä¼˜å…ˆè¿”å›
                    # åˆ›å»ºä¸€ä¸ªæ–°çš„ç»“æœå¯¹è±¡ï¼Œåˆ†æ•°æå‡0.3ï¼ˆç¡®ä¿æ’åœ¨å‰é¢ï¼‰
                    from src.core.vector_store import VectorSearchResult
                    boosted_result = VectorSearchResult(
                        id=result.id,
                        score=result.score + 0.3,  # æå‡åˆ†æ•°
                        text=result.text,
                        metadata=result.metadata
                    )
                    exact_match_results.append(boosted_result)
                else:
                    boosted_results.append(result)
            
            # åˆå¹¶ç»“æœï¼šå…ˆè¿”å›åŒ…å«é‡è¦çŸ­è¯­çš„ï¼Œå†è¿”å›å…¶ä»–ç»“æœ
            vector_results = exact_match_results + boosted_results
            logger.info(f"âœ… å…³é”®è¯å¢å¼º: {len(exact_match_results)} ä¸ªç»“æœåŒ…å«é‡è¦çŸ­è¯­ï¼Œå·²æå‡ä¼˜å…ˆçº§")
        
        # å¦‚æœå‘é‡æ£€ç´¢ç»“æœè¾ƒå°‘ï¼Œå°è¯•å…³é”®è¯åŒ¹é…
        if len(vector_results) < top_k:
            # æå–æŸ¥è¯¢å…³é”®è¯
            keywords = self._extract_keywords(query)
            if keywords:
                # å°è¯•ä½¿ç”¨å…³é”®è¯è¿›è¡ŒäºŒæ¬¡æ£€ç´¢
                keyword_results = self._keyword_search(keywords, top_k)
                # åˆå¹¶ç»“æœï¼Œå»é‡
                vector_results = self._merge_results(vector_results, keyword_results, top_k)
        
        # è¿”å›top_kä¸ªç»“æœ
        return vector_results[:top_k]
    
    def _expand_query(self, query: str) -> str:
        """
        æŸ¥è¯¢æ‰©å±•ï¼šå¯¹äºçŸ­æŸ¥è¯¢ï¼ˆç‰¹åˆ«æ˜¯æ•°å­—ç¼–å·ï¼‰ï¼Œæ‰©å±•æŸ¥è¯¢ä»¥æä¾›æ›´å¤šä¸Šä¸‹æ–‡
        
        Args:
            query: åŸå§‹æŸ¥è¯¢
            
        Returns:
            æ‰©å±•åçš„æŸ¥è¯¢
        """
        import re
        
        # å¦‚æœæŸ¥è¯¢å¾ˆçŸ­ï¼ˆå°‘äº10ä¸ªå­—ç¬¦ï¼‰ï¼Œå°è¯•æ‰©å±•
        if len(query.strip()) < 10:
            # æ£€æµ‹æ•°å­—ç¼–å·ï¼ˆå¦‚"ç¬¬åä¸€æ¡"ã€"ç¬¬ä¸€æ¡"ç­‰ï¼‰
            number_pattern = re.search(r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+æ¡', query)
            if number_pattern:
                # æ‰¾åˆ°ç¼–å·ï¼Œæ‰©å±•æŸ¥è¯¢ï¼šæ·»åŠ "è§„å®š"ã€"å†…å®¹"ã€"æ¡æ¬¾"ç­‰ä¸Šä¸‹æ–‡è¯
                expanded = f"{query} è§„å®š å†…å®¹ æ¡æ¬¾ è¯´æ˜"
                return expanded
        
        # å¦‚æœæŸ¥è¯¢åªåŒ…å«æ•°å­—ç¼–å·ï¼Œä¹Ÿè¿›è¡Œæ‰©å±•
        if re.match(r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+æ¡\s*$', query.strip()):
            expanded = f"{query} è§„å®š å†…å®¹ æ¡æ¬¾ è¯´æ˜"
            return expanded
        
        return query
    
    def _extract_keywords(self, query: str) -> List[str]:
        """æå–æŸ¥è¯¢å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–ï¼šå»é™¤åœç”¨è¯ï¼Œä¿ç•™é‡è¦è¯æ±‡
        stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™'}
        words = query.split()
        keywords = [w for w in words if w not in stop_words and len(w) > 1]
        return keywords
    
    def _keyword_search(self, keywords: List[str], top_k: int) -> List[VectorSearchResult]:
        """åŸºäºå…³é”®è¯çš„æœç´¢ï¼ˆç®€å•å®ç°ï¼šé€šè¿‡å‘é‡æœç´¢å…³é”®è¯ï¼‰"""
        results = []
        for keyword in keywords[:3]:  # åªä½¿ç”¨å‰3ä¸ªå…³é”®è¯
            try:
                keyword_vector = self.embedding_service.embed_text(keyword)
                keyword_results = self.vector_store.search(
                    query_vector=keyword_vector,
                    top_k=top_k,
                    filter_dict=None
                )
                results.extend(keyword_results)
            except Exception:
                continue
        return results
    
    def _merge_results(self, results1: List[VectorSearchResult], results2: List[VectorSearchResult], top_k: int) -> List[VectorSearchResult]:
        """åˆå¹¶æ£€ç´¢ç»“æœï¼Œå»é‡å¹¶æŒ‰åˆ†æ•°æ’åº"""
        from src.utils.logger import logger
        
        # ä½¿ç”¨å­—å…¸å»é‡ï¼ˆåŸºäºIDï¼‰ï¼ŒåŒæ—¶è®°å½•æœ€é«˜åˆ†æ•°
        seen_results = {}  # {id: result}
        
        # å…ˆæ·»åŠ results1ï¼ˆå‘é‡æ£€ç´¢ç»“æœï¼Œä¼˜å…ˆçº§æ›´é«˜ï¼‰
        for result in results1:
            if result.id not in seen_results:
                seen_results[result.id] = result
            else:
                # å¦‚æœå·²å­˜åœ¨ï¼Œä¿ç•™åˆ†æ•°æ›´é«˜çš„ï¼ˆå‡è®¾éƒ½æ˜¯ç›¸ä¼¼åº¦åˆ†æ•°ï¼Œè¶Šå¤§è¶Šå¥½ï¼‰
                if result.score > seen_results[result.id].score:
                    seen_results[result.id] = result
        
        # å†æ·»åŠ results2ï¼ˆå…³é”®è¯æ£€ç´¢ç»“æœï¼‰
        for result in results2:
            if result.id not in seen_results:
                seen_results[result.id] = result
            else:
                # å¦‚æœå·²å­˜åœ¨ï¼Œä¿ç•™åˆ†æ•°æ›´é«˜çš„
                if result.score > seen_results[result.id].score:
                    seen_results[result.id] = result
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æŒ‰åˆ†æ•°æ’åº
        # æ³¨æ„ï¼šFAISSè¿”å›çš„æ˜¯è·ç¦»ï¼ˆè¶Šå°è¶Šå¥½ï¼‰ï¼ŒQdrantè¿”å›çš„æ˜¯ç›¸ä¼¼åº¦ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
        # è¿™é‡Œå‡è®¾å·²ç»ç»Ÿä¸€ä¸ºç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
        merged = list(seen_results.values())
        merged.sort(key=lambda x: x.score, reverse=True)
        
        logger.debug(f"åˆå¹¶æ£€ç´¢ç»“æœ: {len(results1)} + {len(results2)} -> {len(merged)} (å»é‡å)")
        
        return merged[:top_k]
    
    def retrieve_with_scores(
        self,
        query: str,
        top_k: Optional[int] = None,
        filter_dict: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """
        æ£€ç´¢ç›¸å…³æ–‡æ¡£å¹¶è¿”å›è¯¦ç»†ä¿¡æ¯
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            filter_dict: è¿‡æ»¤æ¡ä»¶
            
        Returns:
            åŒ…å«è¯¦ç»†ä¿¡æ¯çš„ç»“æœåˆ—è¡¨
        """
        results = self.retrieve(query, top_k, filter_dict)
        
        return [
            {
                "id": result.id,
                "text": result.text,
                "score": result.score,
                "metadata": result.metadata
            }
            for result in results
        ]
    
    def get_context_text(
        self,
        query: str,
        top_k: Optional[int] = None,
        separator: str = "\n\n"
    ) -> str:
        """
        è·å–æ£€ç´¢ç»“æœçš„ä¸Šä¸‹æ–‡æ–‡æœ¬
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            separator: æ–‡æœ¬åˆ†éš”ç¬¦
            
        Returns:
            åˆå¹¶çš„ä¸Šä¸‹æ–‡æ–‡æœ¬
        """
        results = self.retrieve(query, top_k)
        
        if not results:
            return ""
        
        texts = [result.text for result in results]
        return separator.join(texts)


if __name__ == "__main__":
    """æµ‹è¯•æ£€ç´¢æœåŠ¡"""
    print("=" * 60)
    print("æ£€ç´¢æœåŠ¡æµ‹è¯•")
    print("=" * 60)
    print()
    print("â„¹ï¸  æ£€ç´¢æœåŠ¡éœ€è¦é…åˆå‘é‡å­˜å‚¨ä½¿ç”¨")
    print("   è¯·å‚è€ƒå®Œæ•´çš„é›†æˆæµ‹è¯•")

