#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Embedding æœåŠ¡
æ”¯æŒæœ¬åœ°æ¨¡å‹å’Œ API è°ƒç”¨
"""

from typing import List, Optional
import numpy as np
from pathlib import Path

from config.settings import settings


class EmbeddingService:
    """Embedding æœåŠ¡ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ– Embedding æœåŠ¡"""
        self.model_type = settings.EMBEDDING_MODEL_TYPE
        self.model_name = settings.EMBEDDING_MODEL_NAME
        self.dimension = settings.VECTOR_DIMENSION
        self.batch_size = settings.EMBEDDING_BATCH_SIZE
        
        self.model = None
        self._initialize_model()
    
    def _initialize_model(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        if self.model_type == "local":
            self._load_local_model()
        elif self.model_type == "api":
            self._setup_api_client()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {self.model_type}")
    
    def _load_local_model(self):
        """åŠ è½½æœ¬åœ°æ¨¡å‹"""
        try:
            from sentence_transformers import SentenceTransformer
            
            model_path = settings.get_embedding_model_path()
            if model_path and model_path.exists():
                print(f"ğŸ“¦ åŠ è½½æœ¬åœ° Embedding æ¨¡å‹: {model_path}")
                self.model = SentenceTransformer(str(model_path))
            else:
                print(f"ğŸ“¦ ä¸‹è½½ Embedding æ¨¡å‹: {self.model_name}")
                self.model = SentenceTransformer(self.model_name)
            
            print(f"âœ… Embedding æ¨¡å‹åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            raise RuntimeError(f"åŠ è½½æœ¬åœ° Embedding æ¨¡å‹å¤±è´¥: {e}")
    
    def _setup_api_client(self):
        """è®¾ç½® API å®¢æˆ·ç«¯"""
        try:
            from openai import OpenAI
            
            self.model = OpenAI(
                api_key=settings.EMBEDDING_API_KEY,
                base_url=settings.EMBEDDING_API_BASE
            )
            print(f"âœ… Embedding API å®¢æˆ·ç«¯è®¾ç½®æˆåŠŸ")
            
        except Exception as e:
            raise RuntimeError(f"è®¾ç½® Embedding API å®¢æˆ·ç«¯å¤±è´¥: {e}")
    
    def embed_text(self, text: str) -> np.ndarray:
        """
        å¯¹å•ä¸ªæ–‡æœ¬è¿›è¡Œå‘é‡åŒ–
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            æ–‡æœ¬å‘é‡
        """
        if not text or not text.strip():
            raise ValueError("æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
        
        return self.embed_texts([text])[0]
    
    def embed_texts(self, texts: List[str]) -> List[np.ndarray]:
        """
        å¯¹å¤šä¸ªæ–‡æœ¬è¿›è¡Œæ‰¹é‡å‘é‡åŒ–
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            å‘é‡åˆ—è¡¨
        """
        if not texts:
            return []
        
        # è¿‡æ»¤ç©ºæ–‡æœ¬
        valid_texts = [t for t in texts if t and t.strip()]
        if not valid_texts:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æœ¬")
        
        if self.model_type == "local":
            return self._embed_with_local_model(valid_texts)
        else:
            return self._embed_with_api(valid_texts)
    
    def _embed_with_local_model(self, texts: List[str]) -> List[np.ndarray]:
        """ä½¿ç”¨æœ¬åœ°æ¨¡å‹è¿›è¡Œå‘é‡åŒ–"""
        try:
            # æ‰¹é‡ç¼–ç 
            embeddings = self.model.encode(
                texts,
                batch_size=self.batch_size,
                show_progress_bar=False,
                convert_to_numpy=True
            )
            
            # è½¬æ¢ä¸ºåˆ—è¡¨
            return [emb.astype('float32') for emb in embeddings]
            
        except Exception as e:
            raise RuntimeError(f"æœ¬åœ°æ¨¡å‹å‘é‡åŒ–å¤±è´¥: {e}")
    
    def _embed_with_api(self, texts: List[str]) -> List[np.ndarray]:
        """ä½¿ç”¨ API è¿›è¡Œå‘é‡åŒ–"""
        try:
            embeddings = []
            
            # åˆ†æ‰¹å¤„ç†
            for i in range(0, len(texts), self.batch_size):
                batch = texts[i:i + self.batch_size]
                
                response = self.model.embeddings.create(
                    model=self.model_name,
                    input=batch,
                    dimensions=self.dimension
                )
                
                batch_embeddings = [
                    np.array(item.embedding, dtype='float32')
                    for item in response.data
                ]
                embeddings.extend(batch_embeddings)
            
            return embeddings
            
        except Exception as e:
            raise RuntimeError(f"API å‘é‡åŒ–å¤±è´¥: {e}")
    
    def get_dimension(self) -> int:
        """è·å–å‘é‡ç»´åº¦"""
        return self.dimension
    
    def get_model_info(self) -> dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            "model_type": self.model_type,
            "model_name": self.model_name,
            "dimension": self.dimension,
            "batch_size": self.batch_size
        }


# å…¨å±€å•ä¾‹
_embedding_service: Optional[EmbeddingService] = None


def get_embedding_service() -> EmbeddingService:
    """è·å– Embedding æœåŠ¡å•ä¾‹"""
    global _embedding_service
    if _embedding_service is None:
        _embedding_service = EmbeddingService()
    return _embedding_service


if __name__ == "__main__":
    """æµ‹è¯• Embedding æœåŠ¡"""
    print("=" * 60)
    print("Embedding æœåŠ¡æµ‹è¯•")
    print("=" * 60)
    print()
    
    try:
        # åˆ›å»ºæœåŠ¡
        service = get_embedding_service()
        print(f"âœ… æœåŠ¡åˆ›å»ºæˆåŠŸ")
        print(f"   {service.get_model_info()}")
        print()
        
        # æµ‹è¯•å•ä¸ªæ–‡æœ¬
        print("ğŸ“ æµ‹è¯•å•ä¸ªæ–‡æœ¬å‘é‡åŒ–...")
        text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
        vector = service.embed_text(text)
        print(f"   æ–‡æœ¬: {text}")
        print(f"   å‘é‡ç»´åº¦: {vector.shape}")
        print(f"   å‘é‡å‰5ç»´: {vector[:5]}")
        print()
        
        # æµ‹è¯•æ‰¹é‡æ–‡æœ¬
        print("ğŸ“ æµ‹è¯•æ‰¹é‡æ–‡æœ¬å‘é‡åŒ–...")
        texts = [
            "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯",
            "æœºå™¨å­¦ä¹ æ˜¯å®ç°äººå·¥æ™ºèƒ½çš„ä¸€ç§æ–¹æ³•",
            "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸ"
        ]
        vectors = service.embed_texts(texts)
        print(f"   æ–‡æœ¬æ•°é‡: {len(texts)}")
        print(f"   å‘é‡æ•°é‡: {len(vectors)}")
        print(f"   æ¯ä¸ªå‘é‡ç»´åº¦: {vectors[0].shape}")
        print()
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        print("ğŸ” è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦...")
        from numpy.linalg import norm
        
        def cosine_similarity(a, b):
            return np.dot(a, b) / (norm(a) * norm(b))
        
        sim_01 = cosine_similarity(vectors[0], vectors[1])
        sim_02 = cosine_similarity(vectors[0], vectors[2])
        sim_12 = cosine_similarity(vectors[1], vectors[2])
        
        print(f"   æ–‡æœ¬0 vs æ–‡æœ¬1: {sim_01:.4f}")
        print(f"   æ–‡æœ¬0 vs æ–‡æœ¬2: {sim_02:.4f}")
        print(f"   æ–‡æœ¬1 vs æ–‡æœ¬2: {sim_12:.4f}")
        print()
        
        print("âœ… Embedding æœåŠ¡æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

